---
title: "Assembly"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    theme: sandstone
---

```{r, include=FALSE}
databasescaled <- 10000
metaquast.file <- snakemake@input[["metaquast"]]
cov.details.file <- snakemake@input[["covdetails"]]
cov.summary.file <- snakemake@input[["covsum"]]
jgi_cov.details.file <- snakemake@input[["jgicovdetails"]]
commonscript.file <- snakemake@input[["commons"]]
lca.file <- snakemake@input[["lca"]]
sig.file <- snakemake@input[["sig"]]
samplenames <- list(sample=snakemake@params[["samples"]])
taxcols <- c("superkingdom","phylum","class","order","family","genus","species")
files <- unlist(c(metaquast.file,cov.details.file,cov.summary.file,jgi_cov.details.file))
source(commonscript.file)
commonOptions(1)
require(tidyr)

metaquast <- readData(metaquast.file, samplenames)
metaquast[, Assembly := NULL]
cov.details <- readData(cov.details.file, samplenames)
cov.summary <-  readData(cov.summary.file, samplenames)
cov.summary[, percmapped:=mappedreads/reads*100]
jgi_cov.details <- readData(jgi_cov.details.file, samplenames)

sig <- readData(sig.file, samplenames)
lca <- readData(lca.file, samplenames)
lca[is.na(lca)] <- ""
lca[, depth:=apply(.SD, 1, function(row)sum(row!="")), .SD=taxcols]
taxdata <- copy(lca)
taxdata <- rbindlist(lapply(split(taxdata, taxdata$sample),fixTaxCounts))
taxdata[taxdata==""] <- "Unclassified"
setnames(taxdata, "count", "N")
setcolorder(taxdata, c("sample", taxcols, "N"))
```

Overview
=================

Row
--------------------------------------

### Application Note

The assembly was done with [MEGAHIT](https://github.com/voutcn/megahit) using the merged and unmerged reads. The analysis of the resulting assemblies was done with [MetaQUAST](http://quast.sf.net/metaquast). The raw reads were mapped onto the assembly with BBmap, once with the parameters as described by the MEGAHIT, aswell as with the parameters used in the paper for MetaBAT 2. For the mapping resulting from the MEGAHIT parameters, the BBmap pileup.sh script and for MetaBAT 2 the program jgi_summarize_bam_contig_depths included in MetaBAT2 was used to calculate contig coverage. In jgi_summarize_bam_contig_depths the coverage is corrected for sequencing errors and strain variation.

The Nx values are the length of the contig at which x percent of cumulative contig length is reached (sorted by contig length descending). Lx values are the minimal number of contigs, which is needed to construct x% of the cumulative length.

Taxonomy data is based on the results from Sourmash for the whole assembly.


> Rendered at: `r Sys.time()`.

Row
--------------------------------------

### File Note

```{r}
knitr::kable(genInfoBlock(files))
```
> The table shows the files which have been used to generate this report.


Row
--------------------------------------


### MetaQUAST

```{r}
metaquast.visiblecols <- !(grepl("# contigs (",colnames(metaquast),fixed=T)|(grepl("Total length (",colnames(metaquast),fixed=T)))
DT::datatable(metaquast[,..metaquast.visiblecols])
```

> Data on the samples as calculated by MetaQUAST. BUSCO searches for Universal-Single Copy Orthologs (Bacteria dataset) in the entire sample, this should be always almost complete. The mapping of the reads was performed as described by the authors of MEGAHIT.

Row
-----------------------------------------------------------------------

### N50/N75 L50/75

```{r}
metaquast.stats_molten = metaquast[,c("sample",colnames(metaquast)[grepl("[NL]\\d\\d",colnames(metaquast))]),with=F]
metaquast.stats_molten = melt(metaquast.stats_molten,id.vars="sample")
metaquast.stats_molten[,NL:=gsub("([NL])\\d\\d","\\1",variable)]
ggplotly(ggplot(metaquast.stats_molten, aes(x=sample, y=value, fill=variable)) + 
  geom_bar(stat = "identity",position = "dodge")+facet_wrap(~NL,scales = "free_y")+theme(axis.text.x = element_text(angle = 33))+xlab("For L: number of contigs  For N: size of contig in bp") + xlab("Sample"))
```

> The N and L valuesfor 50 and 75, calculated by MetaQUAST.


### Number of Contigs
```{r}
metaquast.contigs_molten = metaquast[,c("sample",colnames(metaquast)[grepl("# contigs (",colnames(metaquast),fixed=T)]),with=F]
metaquast.contigs_molten = melt(metaquast.contigs_molten,id.vars="sample")
ggplotly(ggplot(metaquast.contigs_molten, aes(x=sample, y=value, fill=sample)) +  
  geom_bar(stat = "identity",position = "dodge")+ facet_wrap(~variable,scales = "free_y") + xlab("Sample") + ylab("Number of contigs")+theme(legend.position = "none")+theme(axis.text.x = element_text(angle = 33)))
```

> The number of contigs above a certain size.


Row
-----------------------------------------------------------------------

### Nx

```{r}
setorder(cov.details,sample,-len)
cov.details[,cumLength := cumsum(len), by=sample]
cov.details[,Nx := cumLength/sum(len)*100, by=sample]
nxdat = cov.details[,approx(Nx,len,seq(0,100,0.05)),by=sample][!is.na(y)]
ggplotly(ggplot(nxdat) + aes(x=x,y=y,color=sample) + geom_line()+  scale_x_reverse() + xlab("Nx") +ylab("Length of the contig in bp")+labs(color="Sample"))
```

> The Nx plot

### Lx

```{r}
cov.details[,Lx := 1:.N,by=sample]
lxdat = cov.details[,approx(Nx,Lx,seq(0,100,0.05)),by=sample][!is.na(y)]
ggplotly(ggplot(lxdat) + aes(x=x,y=y,color=sample) + geom_line()+  scale_x_reverse() + xlab("Lx") + ylab("Number of contigs")+labs(color="Sample"))

```

Row
-----------------------------------------------------------------------

### Coverage
```{r}
cov.summary.vis=cov.summary[,.(Sample=sample,Reads=reads,`Mapped reads`=mappedreads,`Mapped bases`=mappedbp,`Number of contigs`=contigs,`Total Length`=contigbp,`Mapped reads (%)`=round(percmapped,1),`Properly paired Reads`=round(properpairsperc,1),`Average coverage`=avgcov,`Std. Dev. Coverage`=stddev,`Contigs with any coverage(%)`=round(contigswithanycovperc,1),`Bases covered(%)`=round(bpswithanycovperc,1))]
DT::datatable(cov.summary.vis)
```

> The coverage summary, calculated by pileup.sh

Row
-----------------------------------------------------------------------

### Coverage Distribution

```{r}
covstats = rbind(data.table(type="PileUp",avcov=cov.details[["avgcov"]],sample=cov.details$sample),data.table(type="JGI",avcov=jgi_cov.details$avgcov,sample=jgi_cov.details$sample))
covstats=covstats[,calculateBoxplotstats(avcov),by=c("sample","type")]
ggplot(covstats) + aes(fill=sample,lower=lower,upper=upper,middle=middle,ymin=ymin,ymax=ymax,x=sample,group=interaction(sample,type)) + geom_boxplot(stat="identity") + facet_grid(cols=vars(type))+theme(legend.position = "none")+xlab("Sample")+ylab("Coverage")
```

> The distribution of the contig coverage, the whiskers extend from the hinges 1.5 times the IQR, but at most to the min/max values. 


Row
-----------------------------------------------------------------------


### Number of hashes

```{r}
ggplotly(ggplot(sig) + aes(x=sample,y=n_hashes,fill=sample,group=sample)+ geom_bar(stat = "identity",position = "stack") +   labs(x="Sample", y="Used hashes", fill="Sample")+theme(legend.position = "none"))
```

> The number of hashes used for each assembly. 

### Hashes classified

```{r}
fraction_classified <- merge(lca[depth==min(depth), .(count=sum(count)), by=sample], sig[, .(sample,n_hashes,scaled)])
fraction_classified[, fraction_classified:=count/n_hashes*databasescaled/scaled*100]
ggplotly(ggplot(fraction_classified) + aes(x=sample,y=fraction_classified,fill=sample,group=sample)+ geom_bar(stat = "identity",position = "stack") +   scale_y_continuous(labels = function(x) paste0(x, "%")) + labs(x="Sample", y="Hashes classified", fill="Sample")+theme(legend.position = "none"))
```

> The number of classified hashes. The percentages were calculated by dividing the reported count by `n_hashes` and the ratio of the sample and database scale factor.


Taxonomy
=================

Row
---------------------------------------


```{r, results="asis"}
drawSampleTaxplots(taxdata)
```
