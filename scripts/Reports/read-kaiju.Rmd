---
title: "Kaiju Read Classification"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    theme: sandstone
---


```{r, include=FALSE}
alignedresults.file <- snakemake@input[["classkaijudata"]]
readanno_sampled_overview.file <- snakemake@input[["readanno_sampled_overview"]]
commonscript.file <- snakemake@input[["commons"]]
threads <- snakemake@threads
samplenames <- list(sample=snakemake@params[["samples"]])
files <- unlist(c(alignedresults.file,readanno_sampled_overview.file))
source(commonscript.file)
commonOptions(threads)
require(matrixStats)
require(stringr)

readanno_sampled_overview <- readData(readanno_sampled_overview.file, samplenames)

alignedresults <- readData(alignedresults.file, samplenames, readfun=function(...)fread(..., select = c("lengthorscore", "taxid", "tax", "classified", "match_ascs"), sep="\t", fill=T))
alignedresults.counts <- alignedresults[, .N, by=c("sample","classified")]
alignedresults <- alignedresults[classified=="C",]
alignedresults[,match_ascs:=str_count(match_ascs, fixed(","))]


taxtosplit <- alignedresults[, unique(tax)]
taxsplit <- tstrsplit(taxtosplit, split=";", fixed=T, names = T, fill="Unclassified")
taxsplit <- lapply(taxsplit, trimws)
taxsplit <- lapply(taxsplit, function(col){res=col; res[res=="NA"]=NA; res})
taxdata <- data.table(tax=taxtosplit)
taxdata[,( names(taxsplit)):=taxsplit]
rm(taxtosplit, taxsplit)
taxcols <- c("superkingdom", "phylum", "class", "order", "family", "genus", "species")
setnames(taxdata,c("V1", "V2", "V3", "V4", "V5", "V6", "V7"),taxcols)
for(taxi in rev(seq_along(taxcols)[-1])){
  currentlevel <- taxcols[taxi]
	upperlevel <- taxcols[taxi-1]
	taxdata[!is.na(get(currentlevel))&is.na(get(upperlevel)),(upperlevel):="(Taxonomy Gap)"]
}
taxdata[is.na(taxdata)] <- "Unclassified"
setkey(taxdata, "tax")
setkey(alignedresults, "tax")
alignedresults <- taxdata[alignedresults, on=c("tax")]
alignedresults[, tax:=NULL]
rm(taxdata)


levelclass <- alignedresults[, (taxcols), with=F]!="Unclassified"
levelclass <- rowSums(levelclass) # Safe, as the gaps are filled
alignedresults[, taxdepth:=c("None Classified", taxcols)[levelclass+1], ]
rm(levelclass)

taxdata <- alignedresults[, .N, by=c("sample", taxcols)]
```

Overview
=================

Row
--------------------------------------

### Application Note

Kaiju translates the for classification prepared reads into protein sequences and tries to find exact hits and applies a lowest common ancestor search if multiple good quality hits are found, in contrast to SINA this is not a requirement and in the case of only one good hit, this classification will be reported.The default "greedy" mode in Kaiju allows amino acid substitions. The exact database can be specified in the configuration, but the default is the entirety of the NCBI non-reundant protein database.

A Krona plot is available.

> Rendered at: `r Sys.time()`.

Row
--------------------------------------

### File Note

```{r}
knitr::kable(genInfoBlock(files))
```
> The table shows the files which have been used to generate this report.



Row
---------------------------------------

### Score/Length (depending on the mode) distribution

```{r}
dens = alignedresults[,density(lengthorscore)[c("x","y")],by=sample]
dens = dens[x<=max(alignedresults$lengthorscore)&x>=min(alignedresults$lengthorscore)]
ggplotly(ggplot(dens) + aes(x=x,y=y,color=sample) + geom_line() + scale_color_brewer(palette  = sample_palette)+ xlab("Alignment Score or Length") + ylab("(Estimated) Density") + labs(color="Sample"))
```

> The disitrbution (estimated density) of the alignment scores/lenghts. For greedy(default) it is the score, for the MEM mode, it is the length.


### Hit counts

```{r}
alignedresults.counts[,rel:=N/sum(N)*100,by=sample]
ggplotly(ggplot(alignedresults.counts[classified=="C",]) + aes(x=sample,y=rel,fill=sample,group=sample)+ geom_bar(stat = "identity",position = "stack") +  scale_fill_brewer(palette = sample_palette)+ scale_y_continuous(labels = function(x) paste0(x, "%"))+ xlab("Sample") + ylab("Classified Reads")+theme(legend.position = "none"))
```

> The relative number of hits in each sample. This includes assignment to the "Root" taxid and "Cellular Organisms" for example.

Row
---------------------------------------


### Classification depth

```{r}
depth=alignedresults[,.N,by=c("sample","taxdepth")]
depth[,rel:=N/sum(N)*100,by="sample"]
depth[,taxdepth:=factor(taxdepth,levels =rev(c("None Classified",taxcols)))]
ggplotly(ggplot(depth)+aes(x=sample,y=taxdepth,fill=rel) + geom_raster()+scale_fill_continuous(type = "viridis") + labs(fill="% of Classified\n Reads")+xlab("Sample")+ylab("Deepest Level"))
```

> The relative percentage of the deppest classification level for the reads in each sample. While only reads reported as "classified" by Kaiju are analyzed in this report, the assigments to "Cellular Organisms" or "Root" still lack the superkingdom assignment and are shown in this report as "Unclassified"/"None Classified"

### Number of references selected for each query

```{r}
dat = alignedresults[,.N,by=c("sample","match_ascs")]
dat[,rel:=N/sum(N)*100,by=sample]
ggplotly(ggplot(dat) + aes(x=match_ascs,y=rel,color=sample) + geom_line() + scale_color_brewer(palette  = sample_palette)+ xlab("Number of References used") + ylab("% of Classified\n Reads") + labs(color="Sample") + scale_y_continuous(labels = function(x) paste0(x, "%")))
```


>The number of references Kaiju used to determine the classification of a read. When most reads are only assigned to one reference, the high depth of Kaiju is questionable, but the paper describing the tool shows, that a high precision at the genus level is achieved.

Taxonomy
=================

Row
---------------------------------------


```{r, results="asis"}
drawSampleTaxplots(taxdata)
```

